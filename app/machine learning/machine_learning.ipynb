{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries necessary for machine learning\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/tete/Desktop/2025 Spring Modules/COMP30830 Software Engineering/COMP30830-SE-Group11-Dublin-Bike-Sharing-System/app/machine learning/machine_learning.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tete/Desktop/2025%20Spring%20Modules/COMP30830%20Software%20Engineering/COMP30830-SE-Group11-Dublin-Bike-Sharing-System/app/machine%20learning/machine_learning.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m file_paths \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_folder, \u001b[39m\"\u001b[39m\u001b[39mMachineLearningData_*.csv\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tete/Desktop/2025%20Spring%20Modules/COMP30830%20Software%20Engineering/COMP30830-SE-Group11-Dublin-Bike-Sharing-System/app/machine%20learning/machine_learning.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Read and concatenate all CSV files into one DataFrame\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tete/Desktop/2025%20Spring%20Modules/COMP30830%20Software%20Engineering/COMP30830-SE-Group11-Dublin-Bike-Sharing-System/app/machine%20learning/machine_learning.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([pd\u001b[39m.\u001b[39mread_csv(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m file_paths], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tete/Desktop/2025%20Spring%20Modules/COMP30830%20Software%20Engineering/COMP30830-SE-Group11-Dublin-Bike-Sharing-System/app/machine%20learning/machine_learning.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Handle missing values (drop rows with NaN in lagged features)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tete/Desktop/2025%20Spring%20Modules/COMP30830%20Software%20Engineering/COMP30830-SE-Group11-Dublin-Bike-Sharing-System/app/machine%20learning/machine_learning.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m data\u001b[39m.\u001b[39mdropna(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/comp30830/lib/python3.13/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m    385\u001b[0m     ignore_index\u001b[39m=\u001b[39mignore_index,\n\u001b[1;32m    386\u001b[0m     join\u001b[39m=\u001b[39mjoin,\n\u001b[1;32m    387\u001b[0m     keys\u001b[39m=\u001b[39mkeys,\n\u001b[1;32m    388\u001b[0m     levels\u001b[39m=\u001b[39mlevels,\n\u001b[1;32m    389\u001b[0m     names\u001b[39m=\u001b[39mnames,\n\u001b[1;32m    390\u001b[0m     verify_integrity\u001b[39m=\u001b[39mverify_integrity,\n\u001b[1;32m    391\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m    392\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    395\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/comp30830/lib/python3.13/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_integrity \u001b[39m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    447\u001b[0m \u001b[39m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/comp30830/lib/python3.13/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# i need to load in all 5 datasets which is the one dataset combined\n",
    "\n",
    "# Attempt to get the script directory; fallback to os.getcwd() if __file__ is not defined\n",
    "try:\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "# Assuming your notebook is running from \"COMP30830-SE-Group11-Dublin-Bike-Sharing-System/app/machine learning\",\n",
    "# we move up two directories to reach the project root.\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\", \"..\"))\n",
    "\n",
    "# Define the correct path to the 'database' folder inside 'app'\n",
    "data_folder = os.path.join(project_root, \"app\", \"machine learning\")\n",
    "\n",
    "# Get all CSV file paths that match the pattern in the 'database' folder\n",
    "file_paths = glob.glob(os.path.join(data_folder, \"MachineLearningData_*.csv\"))\n",
    "\n",
    "# Read and concatenate all CSV files into one DataFrame\n",
    "data = pd.concat([pd.read_csv(file) for file in file_paths], ignore_index=True)\n",
    "\n",
    "# Handle missing values (drop rows with NaN in lagged features)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"bike_weather_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (drop rows with NaN in lagged features)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['station_id','temperature', 'humidity', 'pressure', 'hour', 'day']\n",
    "target = 'num_bikes_available'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 8.143022150821498\n",
      "R² Score: -4.569177093749488e-05\n"
     ]
    }
   ],
   "source": [
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Coefficients:\n",
      "station_id: -0.00023217307731367119\n",
      "temperature: 0.0030231075501709185\n",
      "humidity: 0.010717418693589288\n",
      "pressure: -0.002050169756292047\n",
      "hour: -0.005113680877276946\n",
      "day: 0.004264426528796764\n",
      "Intercept: 13.383509842413048\n"
     ]
    }
   ],
   "source": [
    "# Display model coefficients\n",
    "print(\"\\nModel Coefficients:\")\n",
    "for feature, coef in zip(features, model.coef_):\n",
    "    print(f\"{feature}: {coef}\")\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to bike_availability_model.joblib\n",
      "Model saved to bike_availability_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "model_filename = \"bike_availability_model.joblib\"\n",
    "joblib.dump(model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "# Save the model to a .pkl file\n",
    "model_filename = \"bike_availability_model.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number of available bikes: 11.985896046344342\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "with open(\"bike_availability_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Define new input data for prediction\n",
    "new_data = pd.DataFrame({\n",
    "    'station_id': [32],\n",
    "    'temperature': [20],\n",
    "    'humidity': [60],\n",
    "    'pressure': [1002.94],\n",
    "    'hour': [9],\n",
    "    'day': [2]  # Example: 0 = Monday, 1 = Tuesday, etc.\n",
    "})\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(new_data)\n",
    "# Output prediction\n",
    "print(f\"Predicted number of available bikes: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predice_based_on_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number of available bikes in Dublin on 2024-02-25 at 09:00: 12.002546949419461\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the trained model\n",
    "with open(\"bike_availability_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "def get_weather_forecast(city, date):\n",
    "    \"\"\"Stub function for weather forecast. Returns fixed weather data: REPLACE WITH CALL TO OPENWEATHER API\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'temperature': 20.0,\n",
    "        'humidity': 60.0,\n",
    "        'wind_speed': 10.0,\n",
    "        'precipitation': 0.0,\n",
    "        'pressure': 1001.10\n",
    "    }\n",
    "\n",
    "def predict_bike_availability(station_id, city, date_str, time_str):\n",
    "    \"\"\"Predict the number of available bikes for a given city, date, and time.\"\"\"\n",
    "    # Parse input date and time\n",
    "    date_time = datetime.strptime(f\"{date_str} {time_str}\", \"%Y-%m-%d %H:%M\")\n",
    "    hour = date_time.hour\n",
    "    day_of_week = date_time.weekday()\n",
    "\n",
    "    # Use the function for weather forecast\n",
    "    weather_features = get_weather_forecast(city, date_str)\n",
    "    \n",
    "    # Prepare input data for the model\n",
    "    input_data = pd.DataFrame([{\n",
    "        'station_id': station_id,\n",
    "        'temperature': weather_features['temperature'],\n",
    "        'humidity': weather_features['humidity'],\n",
    "        'pressure': weather_features['pressure'],\n",
    "        'hour': hour,\n",
    "        'day': day_of_week\n",
    "    }])\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_data)\n",
    "    return prediction[0]\n",
    "\n",
    "# Example usage\n",
    "city = \"Dublin\"\n",
    "date_str = \"2024-02-25\"\n",
    "time_str = \"09:00\"\n",
    "station_id = 50\n",
    "\n",
    "predicted_bikes = predict_bike_availability(station_id, city, date_str, time_str)\n",
    "print(f\"Predicted number of available bikes in {city} on {date_str} at {time_str}: {predicted_bikes}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp30830python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
